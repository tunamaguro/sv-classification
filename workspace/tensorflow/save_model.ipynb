{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00e29ae6-aa89-4ece-8e34-b39a5ec7e213",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "880f6034-756e-47e3-96cc-d3a306291bc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9.1\n",
      "Num GPUs Available:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-31 19:54:55.376559: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:961] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-08-31 19:54:55.403224: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:961] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-08-31 19:54:55.403552: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:961] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "print(tf.version.VERSION)\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices(\"GPU\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4cde7a2b-85ce-4ec6-a2d3-c288802355d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11490434/11490434 [==============================] - 2s 0us/step\n"
     ]
    }
   ],
   "source": [
    "(train_images, train_labels), (\n",
    "    test_images,\n",
    "    test_labels,\n",
    ") = keras.datasets.mnist.load_data()\n",
    "\n",
    "size = 1000\n",
    "image_size = 28 * 28\n",
    "\n",
    "train_labels = train_labels[:size]\n",
    "test_labels = test_labels[:size]\n",
    "\n",
    "train_images = train_images[:size].reshape(-1, image_size) / 255.0\n",
    "test_images = test_images[:size].reshape(-1, image_size) / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "efc50c01-dbd9-4364-9cc9-4be9386f18db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-31 20:02:45.011736: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-08-31 20:02:45.013905: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:961] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-08-31 20:02:45.014372: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:961] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-08-31 20:02:45.014710: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:961] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-08-31 20:02:45.809283: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:961] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-08-31 20:02:45.809536: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:961] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-08-31 20:02:45.809547: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2022-08-31 20:02:45.809718: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:961] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-08-31 20:02:45.809775: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5423 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 512)               401920    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                2570      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 535,818\n",
      "Trainable params: 535,818\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def create_model():\n",
    "    model = keras.models.Sequential(\n",
    "        [\n",
    "            keras.layers.Dense(512, activation=\"relu\", input_shape=(image_size,)),\n",
    "            keras.layers.Dropout(0.5),\n",
    "            keras.layers.Dense(256, activation=\"relu\"),\n",
    "            keras.layers.Dropout(0.5),\n",
    "            keras.layers.Dense(10),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=\"adam\",\n",
    "        loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "        metrics=[tf.metrics.SparseCategoricalAccuracy()],\n",
    "    )\n",
    "    return model\n",
    "\n",
    "model=create_model()\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e8fae43-bed3-465a-969d-8a7c8c68bfff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-31 20:05:24.844834: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/32 [=======================>......] - ETA: 0s - loss: 1.8124 - sparse_categorical_accuracy: 0.4062\n",
      "Epoch 1: saving model to training_1/cp.ckpt\n",
      "32/32 [==============================] - 4s 14ms/step - loss: 1.7408 - sparse_categorical_accuracy: 0.4300 - val_loss: 0.9616 - val_sparse_categorical_accuracy: 0.7350\n",
      "Epoch 2/10\n",
      "25/32 [======================>.......] - ETA: 0s - loss: 0.8125 - sparse_categorical_accuracy: 0.7250\n",
      "Epoch 2: saving model to training_1/cp.ckpt\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.7925 - sparse_categorical_accuracy: 0.7400 - val_loss: 0.6007 - val_sparse_categorical_accuracy: 0.8110\n",
      "Epoch 3/10\n",
      "28/32 [=========================>....] - ETA: 0s - loss: 0.5677 - sparse_categorical_accuracy: 0.8214\n",
      "Epoch 3: saving model to training_1/cp.ckpt\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.5641 - sparse_categorical_accuracy: 0.8250 - val_loss: 0.5150 - val_sparse_categorical_accuracy: 0.8380\n",
      "Epoch 4/10\n",
      "27/32 [========================>.....] - ETA: 0s - loss: 0.4377 - sparse_categorical_accuracy: 0.8715\n",
      "Epoch 4: saving model to training_1/cp.ckpt\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.4274 - sparse_categorical_accuracy: 0.8700 - val_loss: 0.5179 - val_sparse_categorical_accuracy: 0.8370\n",
      "Epoch 5/10\n",
      "27/32 [========================>.....] - ETA: 0s - loss: 0.3239 - sparse_categorical_accuracy: 0.9028\n",
      "Epoch 5: saving model to training_1/cp.ckpt\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.3201 - sparse_categorical_accuracy: 0.9030 - val_loss: 0.4714 - val_sparse_categorical_accuracy: 0.8420\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.2618 - sparse_categorical_accuracy: 0.9220\n",
      "Epoch 6: saving model to training_1/cp.ckpt\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.2618 - sparse_categorical_accuracy: 0.9220 - val_loss: 0.4186 - val_sparse_categorical_accuracy: 0.8570\n",
      "Epoch 7/10\n",
      "23/32 [====================>.........] - ETA: 0s - loss: 0.2438 - sparse_categorical_accuracy: 0.9307\n",
      "Epoch 7: saving model to training_1/cp.ckpt\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.2316 - sparse_categorical_accuracy: 0.9340 - val_loss: 0.3997 - val_sparse_categorical_accuracy: 0.8740\n",
      "Epoch 8/10\n",
      "23/32 [====================>.........] - ETA: 0s - loss: 0.1899 - sparse_categorical_accuracy: 0.9470\n",
      "Epoch 8: saving model to training_1/cp.ckpt\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1869 - sparse_categorical_accuracy: 0.9460 - val_loss: 0.4062 - val_sparse_categorical_accuracy: 0.8620\n",
      "Epoch 9/10\n",
      "25/32 [======================>.......] - ETA: 0s - loss: 0.1393 - sparse_categorical_accuracy: 0.9588\n",
      "Epoch 9: saving model to training_1/cp.ckpt\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1454 - sparse_categorical_accuracy: 0.9540 - val_loss: 0.3933 - val_sparse_categorical_accuracy: 0.8670\n",
      "Epoch 10/10\n",
      "24/32 [=====================>........] - ETA: 0s - loss: 0.1493 - sparse_categorical_accuracy: 0.9531\n",
      "Epoch 10: saving model to training_1/cp.ckpt\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1533 - sparse_categorical_accuracy: 0.9540 - val_loss: 0.3917 - val_sparse_categorical_accuracy: 0.8760\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f62d45f9670>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_path = \"training_1/cp.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "cp_callback = keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_path, save_weights_only=True, verbose=1\n",
    ")\n",
    "\n",
    "model.fit(train_images,train_labels,epochs=10,validation_data=(test_images,test_labels),callbacks=[cp_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3568976d-d9cc-40b7-b430-fe87dfdc25be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cp.ckpt.data-00000-of-00001', 'checkpoint', 'cp.ckpt.index']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(checkpoint_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "23a48397-fc61-4887-9558-95e33fe41f17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 - 0s - loss: 2.3192 - sparse_categorical_accuracy: 0.0990 - 154ms/epoch - 5ms/step\n",
      "トレーニング前, acc: 9.90%\n"
     ]
    }
   ],
   "source": [
    "model=create_model()\n",
    "\n",
    "loss,acc=model.evaluate(test_images,test_labels,verbose=2)\n",
    "print(\"トレーニング前, acc:{:5.2f}%\".format(100*acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8334d999-eb98-4bfb-8f54-121da1a19db4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 - 0s - loss: 0.3917 - sparse_categorical_accuracy: 0.8760 - 93ms/epoch - 3ms/step\n",
      "トレーニング後, acc:87.60%\n"
     ]
    }
   ],
   "source": [
    "model.load_weights(checkpoint_path)\n",
    "\n",
    "loss, acc = model.evaluate(test_images, test_labels, verbose=2)\n",
    "print(\"トレーニング後, acc:{:5.2f}%\".format(100 * acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "22d09a79-a76d-4b32-8137-029bfec72694",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 20: saving model to training_2/cp-0020.ckpt\n",
      "\n",
      "Epoch 40: saving model to training_2/cp-0040.ckpt\n",
      "\n",
      "Epoch 60: saving model to training_2/cp-0060.ckpt\n",
      "\n",
      "Epoch 80: saving model to training_2/cp-0080.ckpt\n",
      "\n",
      "Epoch 100: saving model to training_2/cp-0100.ckpt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f62c8492760>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_path = \"training_2/cp-{epoch:04d}.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "cp_callback = keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_path,\n",
    "    verbose=1,\n",
    "    save_weights_only=True,\n",
    "    save_freq=5 * batch_size,\n",
    ")\n",
    "\n",
    "model = create_model()\n",
    "\n",
    "model.save_weights(checkpoint_path.format(epoch=0))\n",
    "\n",
    "model.fit(\n",
    "    train_images,\n",
    "    train_labels,\n",
    "    epochs=100,\n",
    "    batch_size=batch_size,\n",
    "    callbacks=[cp_callback],\n",
    "    validation_data=(test_images, test_labels),\n",
    "    verbose=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cbfc382f-a076-41d9-9b41-7a6b90344797",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cp-0060.ckpt.data-00000-of-00001',\n",
       " 'cp-0100.ckpt.data-00000-of-00001',\n",
       " 'cp-0000.ckpt.index',\n",
       " 'checkpoint',\n",
       " 'cp-0060.ckpt.index',\n",
       " 'cp-0100.ckpt.index',\n",
       " 'cp-0020.ckpt.index',\n",
       " 'cp-0080.ckpt.data-00000-of-00001',\n",
       " 'cp-0020.ckpt.data-00000-of-00001',\n",
       " 'cp-0080.ckpt.index',\n",
       " 'cp-0040.ckpt.data-00000-of-00001',\n",
       " 'cp-0000.ckpt.data-00000-of-00001',\n",
       " 'cp-0040.ckpt.index']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(checkpoint_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2ef2d405-2672-4d46-b846-a4d9eede89f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'training_2/cp-0100.ckpt'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latest=tf.train.latest_checkpoint(checkpoint_dir)\n",
    "latest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "50f1e9d1-c7de-41d7-aa04-5e3cd3931d01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 - 0s - loss: 0.6188 - sparse_categorical_accuracy: 0.8820 - 147ms/epoch - 5ms/step\n",
      "Restored model, accuracy: 88.20%\n"
     ]
    }
   ],
   "source": [
    "# Create a new model instance\n",
    "model = create_model()\n",
    "\n",
    "# Load the previously saved weights\n",
    "model.load_weights(latest)\n",
    "\n",
    "# Re-evaluate the model\n",
    "loss, acc = model.evaluate(test_images, test_labels, verbose=2)\n",
    "print(\"Restored model, accuracy: {:5.2f}%\".format(100 * acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fa8fb392-0134-469a-ae91-e5a35cbed3c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 - 0s - loss: 0.6188 - sparse_categorical_accuracy: 0.8820 - 154ms/epoch - 5ms/step\n",
      "Restored model, accuracy: 88.20%\n"
     ]
    }
   ],
   "source": [
    "model.save_weights('./checkpoints/my_checkpoint')\n",
    "\n",
    "model=create_model()\n",
    "\n",
    "model.load_weights('./checkpoints/my_checkpoint')\n",
    "loss, acc = model.evaluate(test_images, test_labels, verbose=2)\n",
    "print(\"Restored model, accuracy: {:5.2f}%\".format(100 * acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "50446300-f4b0-44f3-8937-f57d04f3252c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.7116 - sparse_categorical_accuracy: 0.4300\n",
      "Epoch 2/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.8258 - sparse_categorical_accuracy: 0.7330\n",
      "Epoch 3/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6023 - sparse_categorical_accuracy: 0.8110\n",
      "Epoch 4/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.4182 - sparse_categorical_accuracy: 0.8740\n",
      "Epoch 5/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.3449 - sparse_categorical_accuracy: 0.8990\n",
      "Epoch 6/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2594 - sparse_categorical_accuracy: 0.9290\n",
      "Epoch 7/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2057 - sparse_categorical_accuracy: 0.9330\n",
      "Epoch 8/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.1805 - sparse_categorical_accuracy: 0.9460\n",
      "Epoch 9/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.1514 - sparse_categorical_accuracy: 0.9520\n",
      "Epoch 10/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.1111 - sparse_categorical_accuracy: 0.9670\n",
      "Epoch 11/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.1121 - sparse_categorical_accuracy: 0.9630\n",
      "Epoch 12/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0887 - sparse_categorical_accuracy: 0.9780\n",
      "Epoch 13/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0883 - sparse_categorical_accuracy: 0.9730\n",
      "Epoch 14/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0634 - sparse_categorical_accuracy: 0.9820\n",
      "Epoch 15/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0626 - sparse_categorical_accuracy: 0.9830\n",
      "Epoch 16/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0619 - sparse_categorical_accuracy: 0.9840\n",
      "Epoch 17/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0427 - sparse_categorical_accuracy: 0.9880\n",
      "Epoch 18/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0520 - sparse_categorical_accuracy: 0.9820\n",
      "Epoch 19/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0477 - sparse_categorical_accuracy: 0.9880\n",
      "Epoch 20/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0479 - sparse_categorical_accuracy: 0.9870\n",
      "Epoch 21/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0440 - sparse_categorical_accuracy: 0.9880\n",
      "Epoch 22/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0385 - sparse_categorical_accuracy: 0.9900\n",
      "Epoch 23/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0341 - sparse_categorical_accuracy: 0.9930\n",
      "Epoch 24/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0450 - sparse_categorical_accuracy: 0.9870\n",
      "Epoch 25/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0324 - sparse_categorical_accuracy: 0.9950\n",
      "Epoch 26/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0476 - sparse_categorical_accuracy: 0.9900\n",
      "Epoch 27/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0258 - sparse_categorical_accuracy: 0.9950\n",
      "Epoch 28/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0171 - sparse_categorical_accuracy: 0.9990\n",
      "Epoch 29/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0120 - sparse_categorical_accuracy: 0.9970\n",
      "Epoch 30/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0145 - sparse_categorical_accuracy: 0.9980\n",
      "Epoch 31/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0189 - sparse_categorical_accuracy: 0.9930\n",
      "Epoch 32/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0139 - sparse_categorical_accuracy: 0.9970\n",
      "Epoch 33/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0146 - sparse_categorical_accuracy: 0.9980\n",
      "Epoch 34/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0293 - sparse_categorical_accuracy: 0.9920\n",
      "Epoch 35/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0218 - sparse_categorical_accuracy: 0.9930\n",
      "Epoch 36/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0229 - sparse_categorical_accuracy: 0.9910\n",
      "Epoch 37/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0277 - sparse_categorical_accuracy: 0.9940\n",
      "Epoch 38/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0206 - sparse_categorical_accuracy: 0.9930\n",
      "Epoch 39/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0158 - sparse_categorical_accuracy: 0.9950\n",
      "Epoch 40/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0190 - sparse_categorical_accuracy: 0.9930\n",
      "Epoch 41/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0108 - sparse_categorical_accuracy: 0.9960\n",
      "Epoch 42/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0145 - sparse_categorical_accuracy: 0.9950\n",
      "Epoch 43/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0133 - sparse_categorical_accuracy: 0.9960\n",
      "Epoch 44/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0073 - sparse_categorical_accuracy: 0.9990\n",
      "Epoch 45/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0077 - sparse_categorical_accuracy: 0.9980\n",
      "Epoch 46/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0111 - sparse_categorical_accuracy: 0.9960\n",
      "Epoch 47/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0122 - sparse_categorical_accuracy: 0.9970\n",
      "Epoch 48/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0062 - sparse_categorical_accuracy: 0.9980\n",
      "Epoch 49/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0069 - sparse_categorical_accuracy: 0.9990\n",
      "Epoch 50/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0101 - sparse_categorical_accuracy: 0.9960\n",
      "Epoch 51/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0173 - sparse_categorical_accuracy: 0.9960\n",
      "Epoch 52/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0208 - sparse_categorical_accuracy: 0.9920\n",
      "Epoch 53/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0091 - sparse_categorical_accuracy: 0.9990\n",
      "Epoch 54/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0155 - sparse_categorical_accuracy: 0.9940\n",
      "Epoch 55/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0084 - sparse_categorical_accuracy: 0.9990\n",
      "Epoch 56/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0065 - sparse_categorical_accuracy: 0.9990\n",
      "Epoch 57/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0122 - sparse_categorical_accuracy: 0.9970\n",
      "Epoch 58/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0091 - sparse_categorical_accuracy: 0.9980\n",
      "Epoch 59/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0143 - sparse_categorical_accuracy: 0.9970\n",
      "Epoch 60/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0115 - sparse_categorical_accuracy: 0.9990\n",
      "Epoch 61/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0139 - sparse_categorical_accuracy: 0.9950\n",
      "Epoch 62/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0421 - sparse_categorical_accuracy: 0.9880\n",
      "Epoch 63/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0540 - sparse_categorical_accuracy: 0.9830\n",
      "Epoch 64/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0383 - sparse_categorical_accuracy: 0.9820\n",
      "Epoch 65/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0502 - sparse_categorical_accuracy: 0.9820\n",
      "Epoch 66/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0446 - sparse_categorical_accuracy: 0.9850\n",
      "Epoch 67/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0474 - sparse_categorical_accuracy: 0.9840\n",
      "Epoch 68/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0295 - sparse_categorical_accuracy: 0.9860\n",
      "Epoch 69/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0354 - sparse_categorical_accuracy: 0.9890\n",
      "Epoch 70/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0306 - sparse_categorical_accuracy: 0.9890\n",
      "Epoch 71/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0350 - sparse_categorical_accuracy: 0.9900\n",
      "Epoch 72/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0286 - sparse_categorical_accuracy: 0.9870\n",
      "Epoch 73/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0117 - sparse_categorical_accuracy: 0.9980\n",
      "Epoch 74/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0143 - sparse_categorical_accuracy: 0.9970\n",
      "Epoch 75/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0193 - sparse_categorical_accuracy: 0.9960\n",
      "Epoch 76/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0134 - sparse_categorical_accuracy: 0.9960\n",
      "Epoch 77/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0079 - sparse_categorical_accuracy: 0.9990\n",
      "Epoch 78/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0141 - sparse_categorical_accuracy: 0.9940\n",
      "Epoch 79/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0092 - sparse_categorical_accuracy: 0.9970\n",
      "Epoch 80/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0034 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0124 - sparse_categorical_accuracy: 0.9970\n",
      "Epoch 82/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0077 - sparse_categorical_accuracy: 0.9970\n",
      "Epoch 83/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0194 - sparse_categorical_accuracy: 0.9950\n",
      "Epoch 84/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0136 - sparse_categorical_accuracy: 0.9950\n",
      "Epoch 85/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0104 - sparse_categorical_accuracy: 0.9970\n",
      "Epoch 86/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0352 - sparse_categorical_accuracy: 0.9890\n",
      "Epoch 87/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0075 - sparse_categorical_accuracy: 0.9970\n",
      "Epoch 88/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0085 - sparse_categorical_accuracy: 0.9980\n",
      "Epoch 89/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0044 - sparse_categorical_accuracy: 0.9990\n",
      "Epoch 90/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0175 - sparse_categorical_accuracy: 0.9960\n",
      "Epoch 91/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0035 - sparse_categorical_accuracy: 0.9990\n",
      "Epoch 92/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0367 - sparse_categorical_accuracy: 0.9900\n",
      "Epoch 93/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0158 - sparse_categorical_accuracy: 0.9940\n",
      "Epoch 94/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0140 - sparse_categorical_accuracy: 0.9950\n",
      "Epoch 95/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0225 - sparse_categorical_accuracy: 0.9920\n",
      "Epoch 96/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0127 - sparse_categorical_accuracy: 0.9930\n",
      "Epoch 97/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0173 - sparse_categorical_accuracy: 0.9960\n",
      "Epoch 98/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0097 - sparse_categorical_accuracy: 0.9970\n",
      "Epoch 99/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0048 - sparse_categorical_accuracy: 0.9990\n",
      "Epoch 100/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0112 - sparse_categorical_accuracy: 0.9970\n",
      "INFO:tensorflow:Assets written to: saved_model/my_model/assets\n"
     ]
    }
   ],
   "source": [
    "# Create and train a new model instance.\n",
    "model = create_model()\n",
    "model.fit(train_images, train_labels, epochs=100)\n",
    "\n",
    "# Save the entire model as a SavedModel.\n",
    "!mkdir -p saved_model\n",
    "model.save('saved_model/my_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "16ca9a30-84e5-4712-bbb9-52208ffd9ec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my_model\n"
     ]
    }
   ],
   "source": [
    "!ls saved_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c36a6e20-26b1-4459-abef-374857858aae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assets\tkeras_metadata.pb  saved_model.pb  variables\n"
     ]
    }
   ],
   "source": [
    "!ls saved_model/my_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "72e6e485-df9e-4911-b993-a54b1eec8588",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_21 (Dense)            (None, 512)               401920    \n",
      "                                                                 \n",
      " dropout_14 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 256)               131328    \n",
      "                                                                 \n",
      " dropout_15 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 10)                2570      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 535,818\n",
      "Trainable params: 535,818\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "new_model=tf.keras.models.load_model('saved_model/my_model')\n",
    "\n",
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a84cb4-5593-4981-b800-214d909782c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
